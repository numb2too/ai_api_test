import os
import chromadb
import google.generativeai as genai
from flask import Flask, request, jsonify, render_template
from pypdf import PdfReader
from dotenv import load_dotenv

# è¼‰å…¥ .env
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# åˆå§‹åŒ– Gemini
genai.configure(api_key=api_key)

app = Flask(__name__)

# --- åˆå§‹åŒ–å‘é‡è³‡æ–™åº« (ChromaDB) ---
# é€™æœƒåœ¨ä½ å°ˆæ¡ˆç›®éŒ„ä¸‹å»ºç«‹ä¸€å€‹ 'factory_knowledge_db' è³‡æ–™å¤¾ä¾†å­˜è³‡æ–™
chroma_client = chromadb.PersistentClient(path="./factory_knowledge_db")

# å»ºç«‹ä¸€å€‹ Collection (é¡ä¼¼ SQL çš„ Table)ï¼Œåå­—å« 'manuals'
# å¦‚æœå·²ç¶“å­˜åœ¨å°±ç›´æ¥è®€å–
collection = chroma_client.get_or_create_collection(name="manuals")


def get_embedding(text):
    """
    å°‡æ–‡å­—è½‰æˆå‘é‡ (Vector)
    ä½¿ç”¨æ¨¡å‹: text-embedding-004 (Google å°ˆé–€åšåµŒå…¥çš„æ¨¡å‹)
    """
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text,
        task_type="retrieval_document",
    )
    return result["embedding"]


def get_query_embedding(text):
    """
    å°‡ä½¿ç”¨è€…çš„å•é¡Œè½‰æˆå‘é‡
    """
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text,
        task_type="retrieval_query",
    )
    return result["embedding"]


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/upload_pdf", methods=["POST"])
def upload_pdf():
    """
    æ­¥é©Ÿ 1ï¼šä¸Šå‚³ PDF -> è®€å–æ–‡å­— -> åˆ‡å¡Š -> å­˜å…¥å‘é‡è³‡æ–™åº«
    """
    file = request.files.get("file")
    if not file:
        return jsonify({"error": "æœªä¸Šå‚³æª”æ¡ˆ"}), 400

    # 1. è®€å– PDF æ–‡å­—
    pdf = PdfReader(file)
    text_chunks = []

    # ç°¡å–®çš„åˆ‡å¡Šé‚è¼¯ï¼šä»¥ã€Œé ã€ç‚ºå–®ä½ (å¯¦å‹™ä¸Šé€šå¸¸æœƒæ¯ 500 å­—åˆ‡ä¸€æ®µ)
    for i, page in enumerate(pdf.pages):
        text = page.extract_text()
        # ğŸ‘‡ æ–°å¢é€™å…©è¡Œ Debug ç”¨ (çœ‹çµ‚ç«¯æ©Ÿå°å‡ºä»€éº¼)
        print(f"--- æ­£åœ¨è®€å–ç¬¬ {i+1} é  ---")
        print(text[:200])  # åªå°å‰ 200 å­—æª¢æŸ¥
        print("-----------------------")
        if text:
            # åŠ ä¸Šé ç¢¼æ¨™è¨˜ï¼Œæ–¹ä¾¿ä¹‹å¾Œå¼•ç”¨
            chunk_data = {
                "id": f"{file.filename}_page_{i+1}",
                "text": text,
                "source": f"{file.filename} ç¬¬ {i+1} é ",
            }
            text_chunks.append(chunk_data)

    # 2. è½‰æˆå‘é‡ä¸¦å­˜å…¥ ChromaDB
    # æ³¨æ„ï¼šå¤§é‡è³‡æ–™æ™‚æ‡‰è©²åˆ†æ‰¹è™•ç†ï¼Œé¿å… API è¶…æ™‚
    for chunk in text_chunks:
        # å‘¼å« Google Embedding API
        vector = get_embedding(chunk["text"])

        # å­˜å…¥è³‡æ–™åº«
        collection.upsert(
            ids=[chunk["id"]],  # å”¯ä¸€ ID
            embeddings=[vector],  # å‘é‡æ•¸æ“š
            documents=[chunk["text"]],  # åŸå§‹æ–‡å­—å…§å®¹
            metadatas=[{"source": chunk["source"]}],  # é¡å¤–è³‡è¨Š
        )

    return jsonify({"message": f"æˆåŠŸè™•ç† {len(text_chunks)} å€‹é é¢ä¸¦å­˜å…¥çŸ¥è­˜åº«ï¼"})


@app.route("/ask_rag", methods=["POST"])
def ask_rag():
    """
    æ­¥é©Ÿ 2ï¼šæœå°‹å‘é‡è³‡æ–™åº« -> çµ„è£ Prompt -> è®“ AI å›ç­”
    """
    user_question = request.json.get("question")

    # 1. æŠŠä½¿ç”¨è€…çš„å•é¡Œè®Šæˆå‘é‡
    query_vector = get_query_embedding(user_question)

    # 2. å» ChromaDB æœå°‹ã€Œæœ€åƒã€çš„ 5 å€‹æ®µè½
    results = collection.query(
        query_embeddings=[query_vector], n_results=5  # æ‰¾å‰ 5 å
    )

    # å–å‡ºæ‰¾åˆ°çš„æ–‡å­—èˆ‡ä¾†æº
    retrieved_texts = results["documents"][0]  # List of strings
    retrieved_sources = results["metadatas"][0]  # List of dicts

    # 3. çµ„åˆ Prompt (é€™å°±æ˜¯ RAG çš„ç²¾é«“ï¼šæŠŠè³‡æ–™é¤µçµ¦ AI)
    context_str = "\n\n".join(retrieved_texts)
    source_str = ", ".join([m["source"] for m in retrieved_sources])

    prompt = f"""
    ä½ æ˜¯å·¥å» çš„è³‡æ·±ç¶­ä¿®é¡§å•ã€‚è«‹æ ¹æ“šä»¥ä¸‹çš„ã€åƒè€ƒè³‡æ–™ã€‘å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    å¦‚æœåƒè€ƒè³‡æ–™æ²’æœ‰æåˆ°ç›¸é—œå…§å®¹ï¼Œè«‹ç›´æ¥èªªã€Œè³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€ï¼Œä¸è¦çæ°ã€‚

    ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
    {context_str}

    ã€ä½¿ç”¨è€…å•é¡Œã€‘ï¼š
    {user_question}

    è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸¦åœ¨æœ€å¾Œæ¨™è¨»è³‡è¨Šä¾†æºï¼š({source_str})
    """

    # 4. å‘¼å« Gemini å›ç­”
    model = genai.GenerativeModel("gemini-2.5-flash-lite")
    response = model.generate_content(prompt)

    return jsonify({"answer": response.text, "sources": retrieved_sources})


if __name__ == "__main__":
    app.run(debug=True, port=5003)
